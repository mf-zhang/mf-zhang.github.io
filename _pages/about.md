---
permalink: /
title: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

I'm a PhD student at the University of Tokyo, supervised by Prof. [Yoichi Sato](https://sites.google.com/ut-vision.org/ysato/). My research interests lie in computer vision and multimodal human activity understanding in the first-person perspective.

## üéì Education
* Ph.D. in Information Science @ The University of Tokyo (2026.3 expected)
* M.Sc. in Information Science @ The University of Tokyo (2023.3)
* B.Sc. in Computer Science @ Nanjing University (2020.7)

## üî¨ Research Experience
* Intern at CyberAgent AI Lab, Activity Understanding Team, mentored by [Ryo Yonetani](https://yonetaniryo.github.io) (2024)
* Intern at Shanghai AI Laboratory, OpenGVLab, mentored by [Yifei Huang](https://hyf015.github.io), [Yu Qiao](https://mmlab.siat.ac.cn/yuqiao) (2023)
* Intern at Microsoft Research Asia, Media Computing Group, mentored by [Jinglu Wang](https://www.microsoft.com/en-us/research/people/jinglwa/), [Yan Lu](https://www.microsoft.com/en-us/research/people/yanlu/) (2022)
* Intern at PCL, mentored by [Yinqiang Zheng](https://scholar.google.com/citations?user=JD-5DKcAAAAJ&hl=en), [Feng Lu](https://scholar.google.com/citations?user=9ggbm0QAAAAJ&hl=en) (2021)

## üéñÔ∏è Services and Awards
* JSPS Research Fellowship for Young Scientists DC2
* Reviewer of CVPR, ICCV, ECCV, NeurIPS, AAAI, ICLR, BMVC, TCSVT
* 1st place award of EgoTracks challenge in Ego4D at CVPR 2023
* ‚ÄúStars of Tomorrow‚Äù award by Microsoft Research Asia
* Contracted photographer of Visual China Group


## üìÑ Publications

<div style="display: flex; flex-wrap: wrap; align-items: center;">
    <div style="flex: 1 1 300px;">
        <img src="../images/papers/eccv24_mae.jpeg" alt="ECCV 2024" style="width: 100%; max-width: 300px;"/>
    </div>
    <div style="flex: 1 1 300px; margin-left: 20px;">
        <h3>Masked Video and Body-worn IMU Autoencoder for Egocentric Action Recognition</h3>
        <p><b>Mingfang Zhang</b>, Yifei Huang, Ruicong Liu, Yoichi Sato <br> European Conference on Computer Vision (ECCV), 2024 <br> <a href="http://www.arxiv.org/pdf/2407.06628">Paper</a> and <a href="https://github.com/mf-zhang/IMU-Video-MAE">Code</a></p>
    </div>
</div>

---

<div style="display: flex; flex-wrap: wrap; align-items: center;">
    <div style="flex: 1 1 300px;">
        <img src="../images/papers/cvpr24_egoexo.jpeg" alt="CVPR 2024" style="width: 100%; max-width: 300px;"/>
    </div>
    <div style="flex: 1 1 300px; margin-left: 20px;">
        <h3>EgoExoLearn: A Dataset for Bridging Asynchronous Ego- and Exo-centric View of Procedural Activities in Real World</h3>
        <p>Yifei Huang* , Guo Chen*, Jilan Xu*, <b>Mingfang Zhang</b>*, Lijin Yang, Baoqi Pei, Hongjie Zhang, Lu Dong, Yali Wang, Limin Wang, Yu Qiao (* co-first author) <br> IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2024 <br> <a href="https://arxiv.org/pdf/2403.16182.pdf">Paper</a> and <a href="https://github.com/OpenGVLab/EgoExoLearn">Code</a></p>
    </div>
</div>

---

<div style="display: flex; flex-wrap: wrap; align-items: center;">
    <div style="flex: 1 1 300px;">
        <img src="../images/papers/cvpr24_hand.jpeg" alt="CVPR 2024" style="width: 100%; max-width: 300px;"/>
    </div>
    <div style="flex: 1 1 300px; margin-left: 20px;">
        <h3>Single-to-Dual-View Adaptation for Egocentric 3D Hand Pose Estimation</h3>
        <p>Ruicong Liu, Takehiko Ohkawa, <b>Mingfang Zhang</b>, Yoichi Sato <br> IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2024 <br> <a href="https://arxiv.org/pdf/2403.04381.pdf">Paper</a> and <a href="https://github.com/ut-vision/S2DHand">Code</a></p>
    </div>
</div>

---

<div style="display: flex; flex-wrap: wrap; align-items: center;">
    <div style="flex: 1 1 300px;">
        <img src="../images/papers/cvpr23_mpi.jpeg" alt="CVPR 2023" style="width: 100%; max-width: 300px;"/>
    </div>
    <div style="flex: 1 1 300px; margin-left: 20px;">
        <h3>Structural Multiplane Image: Bridging Neural View Synthesis and 3D Reconstruction</h3>
        <p><b>Mingfang Zhang</b>, Jinglu Wang, Xiao Li, Yifei Huang, Yoichi Sato, Yan Lu <br> IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2023 <br> <a href="https://arxiv.org/pdf/2303.05937.pdf">Paper</a> and <a href="https://github.com/mf-zhang/Structural-MPI">Code</a></p>
    </div>
</div>

---

<div style="display: flex; flex-wrap: wrap; align-items: center;">
    <div style="flex: 1 1 300px;">
        <img src="../images/papers/cvpr22_gaze.jpeg" alt="CVPR 2022" style="width: 100%; max-width: 300px;"/>
    </div>
    <div style="flex: 1 1 300px; margin-left: 20px;">
        <h3>GazeOnce: Real-Time Multi-Person Gaze Estimation</h3>
        <p><b>Mingfang Zhang</b>, Yunfei Liu, Feng Lu <br> IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2022 <br> <a href="https://arxiv.org/abs/2204.09480">Paper</a> and <a href="https://github.com/mf-zhang/GazeOnce">Code</a></p>
    </div>
</div>

---

<div style="display: flex; flex-wrap: wrap; align-items: center;">
    <div style="flex: 1 1 300px;">
        <img src="../images/papers/pami21_dark.jpeg" alt="PAMI 2021" style="width: 100%; max-width: 300px;"/>
    </div>
    <div style="flex: 1 1 300px; margin-left: 20px;">
        <h3>Optical Flow in the Dark</h3>
        <p><b>Mingfang Zhang</b>, Yinqiang Zheng, Feng Lu <br> IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI), 2021 <br> <a href="https://ieeexplore.ieee.org/document/9626625">Paper</a> and <a href="https://github.com/mf-zhang/Optical-Flow-in-the-Dark">Code</a></p>
    </div>
</div>

---

<div style="display: flex; flex-wrap: wrap; align-items: center;">
    <div style="flex: 1 1 300px;">
        <img src="../images/papers/cvpr20_dark.jpeg" alt="CVPR 2020" style="width: 100%; max-width: 300px;"/>
    </div>
    <div style="flex: 1 1 300px; margin-left: 20px;">
        <h3>Optical Flow in the Dark</h3>
        <p>Yinqiang Zheng*, <b>Mingfang Zhang</b>*, Feng Lu (*co-first author) <br> 
        IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2020  <br>  <a href="http://openaccess.thecvf.com/content_CVPR_2020/papers/Zheng_Optical_Flow_in_the_Dark_CVPR_2020_paper.pdf">Paper</a> and <a href="https://github.com/mf-zhang/Optical-Flow-in-the-Dark">Code</a></p>
    </div>
</div>




<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-H5PY7PJR9Q"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-H5PY7PJR9Q');
</script>
